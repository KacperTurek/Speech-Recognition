{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary packages.\n",
    "Make sure you have all of them installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function used to load the audio files.\n",
    "It loads the audio file with its time labels file which is used to cut out the words from the whole recording. Input argument is the name of the file without its format. Function returns two lists, **words** contains arrays with values of the recorded of each word and **labels** contains strings with words corresponging to the recordings. So after using this function we get cut out words without values of recorded noise between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Signal_load(file_name):\n",
    "    signal, sr = librosa.load('Recordings/{}.wav'.format(file_name), sr = 44100)\n",
    "    time_labels = np.loadtxt('Recordings/{}.txt'.format(file_name), dtype='str', delimiter='\\t')\n",
    "    words = []\n",
    "    labels = []\n",
    "    for i in range(0, len(time_labels)):\n",
    "        start = int(float(time_labels[i][0]) * sr)\n",
    "        end = int(float(time_labels[i][1]) * sr)\n",
    "        word = time_labels[i][2]\n",
    "        labels.append(word)\n",
    "        word_signal = signal[start:end]\n",
    "        word_signal = word_signal / np.amax(np.absolute(word_signal))\n",
    "        words.append(word_signal / np.amax(np.absolute(word_signal)))\n",
    "    return words, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function used to extract features from each of the words.\n",
    "It uses mfcc function from librosa package which returns mel-frequency cepstral coefficients of the recording which needs to be given as nupmy array. So input argument to the function is numpy array and it also returns 1D numpy array but with 40 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_features(signal):\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y = signal, sr = 44100, n_mfcc = 40).T, axis = 0)\n",
    "    mfccs = np.array([mfccs])\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First example.\n",
    "In this example recordings of the same person are used. Three of them as training data set and one as testing data set. First all of the recordings are being loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words_1, train_labels_1 = Signal_load('266753_23_M_19_1')\n",
    "train_words_2, train_labels_2 = Signal_load('266753_23_M_20_2')\n",
    "train_words_3, train_labels_3 = Signal_load('266753_23_M_20_3')\n",
    "train_words = train_words_1 + train_words_2 + train_words_3\n",
    "train_labels = train_labels_1 + train_labels_2 + train_labels_3\n",
    "test_words, test_labels = Signal_load('266753_23_M_21_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we extract the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.empty((0, 40))\n",
    "for i in range(0, len(train_words)):\n",
    "    feature = Extract_features(train_words[i])\n",
    "    train_features = np.append(train_features, feature, axis = 0)\n",
    " \n",
    "test_features = np.empty((0, 40))\n",
    "for i in range(0, len(test_words)):\n",
    "    feature = Extract_features(test_words[i])\n",
    "    test_features = np.append(test_features, feature, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create SVC object called clf (it's our classifier). fit function is used to train the classifier with train_features array where each row contains the features of single word and train_labels which is a list where every element is the name of the corresponding recorded word, so it's basically list with names of the classes. After the classifier learned from the training data set we use predict function which uses its new knowledge. It tries to predict names of the classes (in this case words) basing on the features it gets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel = \"linear\", C = 0.025)\n",
    "clf.fit(train_features, train_labels)\n",
    "preds = clf.predict(test_features)\n",
    "print('Accuracy: {}'.format(accuracy_score(test_labels, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is relatively satisfying taking under consideration that training data set is not very large. Below you can see expected results and the ones we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected words: \n",
      "['OTWORZ', 'ZAMKNIJ', 'GARAZ', 'ZROB', 'NASTROJ', 'WLACZ', 'WYLACZ', 'MUZYKE', 'SWIATLO', 'ZAPAL', 'PODNIES', 'ROLETY', 'TELEWIZOR']\n",
      "\n",
      "Predicted words: \n",
      "['OTWORZ' 'ZAMKNIJ' 'GARAZ' 'ZROB' 'NASTROJ' 'TELEWIZOR' 'TELEWIZOR'\n",
      " 'MUZYKE' 'SWIATLO' 'ZAPAL' 'PODNIES' 'TELEWIZOR' 'TELEWIZOR']\n"
     ]
    }
   ],
   "source": [
    "print('Expected words: \\n{}'.format(test_labels))\n",
    "print('\\nPredicted words: \\n{}'.format(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see it more clearly we can present the results on the heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~KacperTurek/132.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heat_map = np.zeros((len(test_labels), len(preds)))\n",
    "for i in range(0, len(test_labels)):\n",
    "    for j in range(0, len(preds)):\n",
    "        if test_labels[i] == preds[j]:\n",
    "            heat_map[i][j] = 1\n",
    "heat_map = (heat_map / 1) * 100            \n",
    "\n",
    "trace = go.Heatmap(z = heat_map,\n",
    "                   x = test_labels,\n",
    "                   y = test_labels,\n",
    "                   colorscale='Viridis')\n",
    "\n",
    "data=[trace]\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the X axis are words that were given as testing data set, so theye are the expected words. On the Y axis are predicted values, so the words we get from our classifier. Colours show the percentage of words being classified to each class, in this case as a word. You can see the exact percentage if you move the cursor over the part of the graph you're interested in. The perfect outcome would be yellow diagonal line that would mean that each word was classified correctly. The results are not bad, we can see that only 3 out of 13 words were wrongly classified. What is interesting is the fact that all wrongly classified words were classified to the same class (TELEWIZOR). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second example.\n",
    "This time we use two recordings from the same person as training data set and  two remaining recordings from that person as testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6153846153846154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~KacperTurek/134.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words_1, train_labels_1 = Signal_load('266753_23_M_19_1')\n",
    "train_words_2, train_labels_2 = Signal_load('266753_23_M_20_2')\n",
    "train_words = train_words_1 + train_words_2\n",
    "train_labels = train_labels_1 + train_labels_2\n",
    "test_words_1, test_labels_1 = Signal_load('266753_23_M_20_3')\n",
    "test_words_2, test_labels_2 = Signal_load('266753_23_M_21_4')\n",
    "test_words = test_words_1 + test_words_2\n",
    "test_labels = test_labels_1 + test_labels_2\n",
    "\n",
    "train_features = np.empty((0, 40))\n",
    "for i in range(0, len(train_words)):\n",
    "    feature = Extract_features(train_words[i])\n",
    "    train_features = np.append(train_features, feature, axis = 0)\n",
    " \n",
    "test_features = np.empty((0, 40))\n",
    "for i in range(0, len(test_words)):\n",
    "    feature = Extract_features(test_words[i])\n",
    "    test_features = np.append(test_features, feature, axis = 0)\n",
    "    \n",
    "clf = SVC(kernel = \"linear\", C = 0.025)\n",
    "clf.fit(train_features, train_labels)\n",
    "preds = clf.predict(test_features)\n",
    "print('Accuracy: {}'.format(accuracy_score(test_labels, preds)))\n",
    "\n",
    "heat_map = np.zeros((len(test_labels_1), len(test_labels_1)))\n",
    "for i in range(0, len(test_labels_1)):\n",
    "    for j in range(0, len(test_labels_1)):\n",
    "        if test_labels[i] == preds[j]:\n",
    "            heat_map[i][j] += 1\n",
    "        if test_labels[i + len(test_labels_1)] == preds[j + len(test_labels_1)]:\n",
    "            heat_map[i][j] += 1\n",
    "heat_map = (heat_map / 2) * 100 \n",
    "            \n",
    "trace = go.Heatmap(z = heat_map,\n",
    "                   x = test_labels_1,\n",
    "                   y = test_labels_1,\n",
    "                   colorscale='Viridis')\n",
    "\n",
    "data=[trace]\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not bad (61.5%). On the heat map we can see that some of the words were classified correctly two times (OTWORZ, GARAZ, MUZYKE, ZAPAL) and of was classified wrongly two times (ZROB). It is shown in yellow colour if the word was classified two times as the same word and in green if it was classified one time as some word, for example NASTROJ was one time classified as NASTROJ and one time as MUZYKE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third example.\n",
    "In this example we're going to use the same audio files, but now all of them will be used as trainig data set and one as testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~KacperTurek/136.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words_1, train_labels_1 = Signal_load('266753_23_M_19_1')\n",
    "train_words_2, train_labels_2 = Signal_load('266753_23_M_20_2')\n",
    "train_words_3, train_labels_3 = Signal_load('266753_23_M_20_3')\n",
    "train_words_4, train_labels_4 = Signal_load('266753_23_M_21_4')\n",
    "train_words = train_words_1 + train_words_2 + train_words_3 + train_words_4\n",
    "train_labels = train_labels_1 + train_labels_2 + train_labels_3 + train_labels_4\n",
    "test_words, test_labels = Signal_load('266753_23_M_21_4')\n",
    "\n",
    "train_features = np.empty((0, 40))\n",
    "for i in range(0, len(train_words)):\n",
    "    feature = Extract_features(train_words[i])\n",
    "    train_features = np.append(train_features, feature, axis = 0)\n",
    " \n",
    "test_features = np.empty((0, 40))\n",
    "for i in range(0, len(test_words)):\n",
    "    feature = Extract_features(test_words[i])\n",
    "    test_features = np.append(test_features, feature, axis = 0)\n",
    "    \n",
    "clf = SVC(kernel = \"linear\", C = 0.025)\n",
    "clf.fit(train_features, train_labels)\n",
    "preds = clf.predict(test_features)\n",
    "print('Accuracy: {}'.format(accuracy_score(test_labels, preds)))\n",
    "\n",
    "heat_map = np.zeros((len(test_labels), len(preds)))\n",
    "for i in range(0, len(test_labels)):\n",
    "    for j in range(0, len(preds)):\n",
    "        if test_labels[i] == preds[j]:\n",
    "            heat_map[i][j] = 1\n",
    "heat_map = (heat_map / 1) * 100 \n",
    "\n",
    "trace = go.Heatmap(z = heat_map,\n",
    "                   x = test_labels,\n",
    "                   y = test_labels,\n",
    "                   colorscale='Viridis')\n",
    "\n",
    "data=[trace]\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As could be foreseen the results are better, accuracy is 100% and on the heat map we can see that ideal outcome mentioned earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth example.\n",
    "Now training data set will again consist of 4 recording from the same person, but testing data set will be one recording from different person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23076923076923078\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~KacperTurek/138.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words_1, train_labels_1 = Signal_load('266753_23_M_19_1')\n",
    "train_words_2, train_labels_2 = Signal_load('266753_23_M_20_2')\n",
    "train_words_3, train_labels_3 = Signal_load('266753_23_M_20_3')\n",
    "train_words_4, train_labels_4 = Signal_load('266753_23_M_21_4')\n",
    "train_words = train_words_1 + train_words_2 + train_words_3 + train_words_4\n",
    "train_labels = train_labels_1 + train_labels_2 + train_labels_3 + train_labels_4\n",
    "test_words, test_labels = Signal_load('266701_23_M_11_1')\n",
    "\n",
    "train_features = np.empty((0, 40))\n",
    "for i in range(0, len(train_words)):\n",
    "    feature = Extract_features(train_words[i])\n",
    "    train_features = np.append(train_features, feature, axis = 0)\n",
    " \n",
    "test_features = np.empty((0, 40))\n",
    "for i in range(0, len(test_words)):\n",
    "    feature = Extract_features(test_words[i])\n",
    "    test_features = np.append(test_features, feature, axis = 0)\n",
    "    \n",
    "clf = SVC(kernel = \"linear\", C = 0.025)\n",
    "clf.fit(train_features, train_labels)\n",
    "preds = clf.predict(test_features)\n",
    "print('Accuracy: {}'.format(accuracy_score(test_labels, preds)))\n",
    "\n",
    "heat_map = np.zeros((len(test_labels), len(preds)))\n",
    "for i in range(0, len(test_labels)):\n",
    "    for j in range(0, len(preds)):\n",
    "        if test_labels[i] == preds[j]:\n",
    "            heat_map[i][j] = 1\n",
    "heat_map = (heat_map / 1) * 100 \n",
    "\n",
    "trace = go.Heatmap(z = heat_map,\n",
    "                   x = test_labels,\n",
    "                   y = test_labels,\n",
    "                   colorscale='Viridis')\n",
    "\n",
    "data=[trace]\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not very good, only 3 out of 13 words were classified correctly. It can mean that if we want to use this code in a smart home system it would have to be configured by the person that will use it, but I think it is commonly used in speech recognition systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth example.\n",
    "In this example we're going to use all of the available recordings (54). There was more of the recordings, but the files were corrupted. Recordings come from 14 people, 13 of them recorded 4 files and 1 of them recorded 2. Files were divided into two equal data sets, training and testing data set. In each one of them is exactly half of the recording from each person, for example 2 of my recordings are in training data set and the other 2 in testing data set and acordingly for every person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6153846153846154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~KacperTurek/140.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words = []\n",
    "train_labels = []\n",
    "for i in range(1, 28):\n",
    "    word, label = Signal_load(str(i))\n",
    "    train_words = train_words + word\n",
    "    train_labels = train_labels + label\n",
    "    \n",
    "train_labels = np.asarray(train_labels)\n",
    "\n",
    "test_words = []\n",
    "test_labels = []\n",
    "for i in range(28, 55):\n",
    "    word, label = Signal_load(str(i))\n",
    "    test_words = test_words + word\n",
    "    test_labels = test_labels + label\n",
    "\n",
    "test_labels = np.asarray(test_labels)\n",
    "\n",
    "train_features = np.empty((0, 40))\n",
    "for i in range(0, len(train_words)):\n",
    "    feature = Extract_features(train_words[i])\n",
    "    train_features = np.append(train_features, feature, axis = 0)\n",
    "    \n",
    "test_features = np.empty((0, 40))\n",
    "for i in range(0, len(test_words)):\n",
    "    feature = Extract_features(test_words[i])\n",
    "    test_features = np.append(test_features, feature, axis = 0)\n",
    "    \n",
    "clf = SVC(kernel = \"linear\", C = 0.025)\n",
    "clf.fit(train_features, train_labels)\n",
    "preds = clf.predict(test_features)\n",
    "print('Accuracy: {}'.format(accuracy_score(test_labels, preds)))\n",
    "\n",
    "heat_map = np.zeros((13, 13))\n",
    "for i in range(0, 27):\n",
    "    for j in range(0, 13):\n",
    "        for k in range(0, 13):\n",
    "            if test_labels[j + (13 * i)] == preds[k + (13 * i)]:\n",
    "                heat_map[j][k] += 1\n",
    "heat_map = (heat_map / 27) * 100\n",
    "\n",
    "trace = go.Heatmap(z = heat_map,\n",
    "                   x = test_labels,\n",
    "                   y = test_labels,\n",
    "                   colorscale='Viridis')\n",
    "\n",
    "data=[trace]\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the results are quite satisfying (61.5%). We can see that 24 out of 27 times (89%) ROLETY was classified correctly and GARAZ 22 times (81%). The worst results we get from classifying ZAMKNIJ, WLACZ and WYLACZ (11 out of 27 times - 41%). WLACZ was 6 times (22%) classified wrongly as SWIATLO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sixth example.\n",
    "This time 41 recordings were used as training data set and remaining 13 as testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6153846153846154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~KacperTurek/142.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words = []\n",
    "train_labels = []\n",
    "for i in range(1, 42):\n",
    "    word, label = Signal_load(str(i))\n",
    "    train_words = train_words + word\n",
    "    train_labels = train_labels + label\n",
    "    \n",
    "train_labels = np.asarray(train_labels)\n",
    "\n",
    "test_words = []\n",
    "test_labels = []\n",
    "for i in range(42, 55):\n",
    "    word, label = Signal_load(str(i))\n",
    "    test_words = test_words + word\n",
    "    test_labels = test_labels + label\n",
    "\n",
    "test_labels = np.asarray(test_labels)\n",
    "\n",
    "train_features = np.empty((0, 40))\n",
    "for i in range(0, len(train_words)):\n",
    "    feature = Extract_features(train_words[i])\n",
    "    train_features = np.append(train_features, feature, axis = 0)\n",
    "    \n",
    "test_features = np.empty((0, 40))\n",
    "for i in range(0, len(test_words)):\n",
    "    feature = Extract_features(test_words[i])\n",
    "    test_features = np.append(test_features, feature, axis = 0)\n",
    "    \n",
    "clf = SVC(kernel = \"linear\", C = 0.025)\n",
    "clf.fit(train_features, train_labels)\n",
    "preds = clf.predict(test_features)\n",
    "print('Accuracy: {}'.format(accuracy_score(test_labels, preds)))\n",
    "\n",
    "heat_map = np.zeros((13, 13))\n",
    "for i in range(0, 13):\n",
    "    for j in range(0, 13):\n",
    "        for k in range(0, 13):\n",
    "            if test_labels[j + (13 * i)] == preds[k + (13 * i)]:\n",
    "                heat_map[j][k] += 1\n",
    "heat_map = (heat_map / 13) * 100 \n",
    "\n",
    "trace = go.Heatmap(z = heat_map,\n",
    "                   x = test_labels,\n",
    "                   y = test_labels,\n",
    "                   colorscale='Viridis')\n",
    "\n",
    "data=[trace]\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as in the previous example we get 61.5% accuracy. GARAZ and ROLETY gave again the best results, but this time same results we get also from PODNIES and TELEWIZOR (10 out of 13 times - 77%). Again WLACZ gave the wors results (3 out of 13 times - 23%) with WYLACZ (4 out of 13 times - 31%). ZAMKNIJ improved a bit (7 out of 13 times - 54%, previously 41%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seventh example.\n",
    "In this last example we use 53 out of 54 recordings as training data set and one remaining as testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6153846153846154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~KacperTurek/144.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words = []\n",
    "train_labels = []\n",
    "for i in range(1, 54):\n",
    "    word, label = Signal_load(str(i))\n",
    "    train_words = train_words + word\n",
    "    train_labels = train_labels + label\n",
    "    \n",
    "train_labels = np.asarray(train_labels)\n",
    "\n",
    "test_words, test_labels = Signal_load('54')\n",
    "\n",
    "test_labels = np.asarray(test_labels)\n",
    "\n",
    "train_features = np.empty((0, 40))\n",
    "for i in range(0, len(train_words)):\n",
    "    feature = Extract_features(train_words[i])\n",
    "    train_features = np.append(train_features, feature, axis = 0)\n",
    "    \n",
    "test_features = np.empty((0, 40))\n",
    "for i in range(0, len(test_words)):\n",
    "    feature = Extract_features(test_words[i])\n",
    "    test_features = np.append(test_features, feature, axis = 0)\n",
    "    \n",
    "clf = SVC(kernel = \"linear\", C = 0.025)\n",
    "clf.fit(train_features, train_labels)\n",
    "preds = clf.predict(test_features)\n",
    "print('Accuracy: {}'.format(accuracy_score(test_labels, preds)))\n",
    "\n",
    "heat_map = np.zeros((len(test_labels), len(preds)))\n",
    "for i in range(0, len(test_labels)):\n",
    "    for j in range(0, len(preds)):\n",
    "        if test_labels[i] == preds[j]:\n",
    "            heat_map[i][j] = 1\n",
    "heat_map = (heat_map / 1) * 100 \n",
    "\n",
    "trace = go.Heatmap(z = heat_map,\n",
    "                   x = test_labels,\n",
    "                   y = test_labels,\n",
    "                   colorscale='Viridis')\n",
    "\n",
    "data=[trace]\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third time in a row we get 61.5% accuracy. Like before ZAMKNIJ, WLACZ and WYLACZ were classified wrongly, but now also ZROB and MUZYKE was classified not so good. Based on all of the heat maps we can notice a pattern in which some of the words are ofthe classified incorectly (ZAMKNIJ, WLACZ, WYLACZ) and some of them properly (OTWORZ, ROLETY, TELEWIZOR)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
